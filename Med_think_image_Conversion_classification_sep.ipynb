{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e72648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.signal import welch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806c13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Convert to DataFrame\n",
    "def convert_bdf_to_dataframe(bdf_filename):\n",
    "    raw_data = mne.io.read_raw_bdf(bdf_filename, preload=True)\n",
    "    eeg_data_raw = raw_data.get_data()\n",
    "    channel_names = raw_data.ch_names\n",
    "    time_index = raw_data.times\n",
    "    eeg_data = pd.DataFrame(data=eeg_data_raw.T, columns=channel_names, index=time_index)\n",
    "    col_names = ['O1', 'O2', 'F3', 'F4', 'C3' ,'C4' , 'Fp1', 'Fp2']\n",
    "    eeg_data = eeg_data[col_names]\n",
    "    segment_size = 1024\n",
    "    num_segments = len(eeg_data) // segment_size\n",
    "    reduced_df = pd.DataFrame(columns=eeg_data.columns)\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size\n",
    "        segment_data = eeg_data.iloc[start_idx:end_idx]    \n",
    "        mean_values = segment_data.mean()\n",
    "        reduced_df = reduced_df.append(mean_values, ignore_index=True)\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415ff059",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Define a function to extract labels from filenames\n",
    "def extract_label_from_filename(filename):\n",
    "    # Assuming filenames are in the format: subject_task.bdf\n",
    "    task = filename.split('_')[1].split('.')[0]\n",
    "    sub = filename.split('_')[0]\n",
    "    return task, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90303637",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Example code to create a spectrogram image from each EEG channel\n",
    "def eeg_channel_to_spectrogram(channel_data, ch_idx):\n",
    "    plt.specgram(channel_data, NFFT=256, Fs=1000, noverlap=128)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.savefig(f'{ch_idx}_channel_spectrogram.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    image = Image.open(f'{ch_idx}_channel_spectrogram.png')\n",
    "    path = f'{ch_idx}_channel_spectrogram.png'\n",
    "    return image, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4aa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from PIL import Image\n",
    "data_dir = './Rishikest_MIT_Dataset'  # Replace with the path to your .bdf data directory\n",
    "eeg_channel_images = []\n",
    "subject_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5101b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load and preprocess the data\n",
    "\n",
    "output_dir_med = './output_images/Meditation'\n",
    "output_dir_think = './output_images/Thinking'\n",
    "os.makedirs(output_dir_med, exist_ok=True)\n",
    "os.makedirs(output_dir_think, exist_ok=True)\n",
    "i = 1\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.bdf'):\n",
    "        # Convert the .bdf file to a DataFrame\n",
    "        eeg_data = convert_bdf_to_dataframe(os.path.join(data_dir, filename))\n",
    "        \n",
    "        # Extract labels from filenames\n",
    "        label, sub = extract_label_from_filename(filename)\n",
    "        Dirs = ''\n",
    "        subject = f'sub{i}'\n",
    "        if 'med'in label:\n",
    "#             Dirs = f'./output_images/{subject}_Med'\n",
    "            Dirs = f'{output_dir_med}/{subject}'\n",
    "            os.makedirs(Dirs, exist_ok=True)\n",
    "        else:\n",
    "#             Dirs = f'./output_images/{subject}_Think'\n",
    "            Dirs = f'{output_dir_think}/{subject}'\n",
    "            os.makedirs(Dirs, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        for channel_idx in range(eeg_data.shape[1]):\n",
    "            channel_data = eeg_data.iloc[:,channel_idx]\n",
    "            channel_image, path = eeg_channel_to_spectrogram(channel_data, eeg_data.columns[channel_idx])\n",
    "            image_path = os.path.join(Dirs, path)\n",
    "            print(image_path)\n",
    "            channel_image.save(image_path)\n",
    "#             eeg_channel_images.append(image_filename)\n",
    "            if subject not in subject_data:\n",
    "                subject_data[subject] = []\n",
    "            subject_data[subject].append(channel_data)\n",
    "        i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3c7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b13389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./output_images/\"\n",
    "image_size = (256, 256)  # Adjust to your desired image size\n",
    "batch_size = 16  # Adjust as needed\n",
    "validation_split = 0.1  # 20% of the data for validation\n",
    "test_split = 0.1  # 10% of the data for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12590c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 8 classes.\n",
      "Found 0 images belonging to 8 classes.\n",
      "Found 64 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "subfolder_names = os.listdir(data_directory)\n",
    "\n",
    "num_classes = 2  # Specify the number of classes (in this case, 2)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "subfolder_names = os.listdir(data_directory)\n",
    "train_data, test_data = train_test_split(\n",
    "    subfolder_names,\n",
    "    test_size=test_split,\n",
    "    random_state=42,\n",
    "    stratify=None  # No need to stratify with only two classes\n",
    ")\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data,\n",
    "    test_size=validation_split,\n",
    "    random_state=42,\n",
    "    stratify=None  # No need to stratify with only two classes\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Use 'binary' for binary classification\n",
    "    subset='training',\n",
    "    shuffle=True  # Shuffle training data\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Use 'binary' for binary classification\n",
    "    subset='validation',\n",
    "    shuffle=False  # Do not shuffle validation data\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Use 'binary' for binary classification\n",
    "    subset=None,  # Test set should not be a subset of train/val\n",
    "    shuffle=False  # Do not shuffle test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74023268",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "# Fixed for Cats & Dogs color images\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 256\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 100\n",
    "EARLY_STOP_PATIENCE = 10\n",
    "\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_VALIDATION = 10\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 100\n",
    "BATCH_SIZE_VALIDATION = 100\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b01ad66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#resnet_weights_path =  r\"D:\\ML\\ML-codes\\resnet50_weights_.h5\"\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = 'imagenet',input_shape=(256,256,3)))\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bde85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate = 0.01,  momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = IMAGE_RESIZE\n",
    "\n",
    "# data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# train_generator = data_generator.flow_from_directory(\n",
    "#         r\"/workspace/train\",\n",
    "#         target_size=(image_size, image_size),\n",
    "#         batch_size=BATCH_SIZE_TRAINING,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validation_generator = data_generator.flow_from_directory(\n",
    "#         r\"/workspace/test\",\n",
    "#         target_size=(image_size, image_size),\n",
    "#         batch_size=BATCH_SIZE_VALIDATION,\n",
    "#         class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab89380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c293b611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 (resnet50) is not trainable\n",
      "Layer 1 (dense) is trainable\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    # Check if the layer is trainable\n",
    "    if layer.trainable:\n",
    "        print(f\"Layer {i} ({layer.name}) is trainable\")\n",
    "    else:\n",
    "        print(f\"Layer {i} ({layer.name}) is not trainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161caf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVOi7\\AppData\\Local\\Temp\\ipykernel_12480\\1366811886.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit_history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12480\\1366811886.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m fit_history = model.fit_generator(\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH_TRAINING\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2505\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m         )\n\u001b[1;32m-> 2507\u001b[1;33m         return self.fit(\n\u001b[0m\u001b[0;32m   2508\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2509\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\LENOVOi7\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = r'/workspace/resnet50.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
    "\n",
    "\n",
    "fit_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d698a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_history.history.keys())\n",
    "\n",
    "plt.figure(1, figsize = (15,8)) \n",
    "\n",
    "plt.subplot(221)  \n",
    "plt.plot(fit_history.history['accuracy'])  \n",
    "plt.plot(fit_history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "\n",
    "plt.figure(1, figsize = (15,8)) \n",
    "plt.subplot(222)  \n",
    "plt.plot(fit_history.history['loss'])  \n",
    "plt.plot(fit_history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff64654",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = data_generator.flow_from_directory(\n",
    "    directory = r\"/workspace/test\",\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = BATCH_SIZE_TESTING,\n",
    "    class_mode = None,\n",
    "    shuffle = False,\n",
    "    seed = 123\n",
    ")\n",
    "\n",
    "test_generator.reset()\n",
    "\n",
    "pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_generator.classes\n",
    "class_indices = train_generator.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "res_preds = model.predict(test_generator)\n",
    "res_pred_classes = np.argmax(res_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33341fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "res_acc = accuracy_score(true_classes, res_pred_classes)\n",
    "print(\"ResNet50 Model Accuracy with Fine-Tuning: {:.2f}%\".format(res_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3tf2)",
   "language": "python",
   "name": "py3tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
